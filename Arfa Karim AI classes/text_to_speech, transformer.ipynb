{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d0b28f5-af0d-4c31-ac4d-3111f6b47343",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text to speech conversion done successfully\n"
     ]
    }
   ],
   "source": [
    "import pyttsx3\n",
    "\n",
    "# Initialize the text-to-speech engine\n",
    "engine = pyttsx3.init()\n",
    "\n",
    "# setting properties\n",
    "engine.setProperty('rate', 200)\n",
    "engine.setProperty('volume', 1)  \n",
    "voices = engine.getProperty('voices')\n",
    "\n",
    "engine.setProperty('voice', voices[1].id)  #Female voice\n",
    "text = \"Hello! This is an example of converting text to speech using Python.\"\n",
    "\n",
    "# Convert text to speech\n",
    "engine.say(text)\n",
    "\n",
    "# Run the speech engine\n",
    "engine.runAndWait()\n",
    "\n",
    "\n",
    "\n",
    "print(\"text to speech conversion done successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab7fba62-aa8d-4d61-b591-58020affdab1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Microsoft David Desktop - English (United States)'}\n",
      "{'Microsoft Zira Desktop - English (United States)'}\n"
     ]
    }
   ],
   "source": [
    "voices = engine.getProperty('voices')\n",
    "for index, voice in enumerate(voices):\n",
    "    print({voice.name})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d43e03-0c11-41ee-8ec4-604ca6205062",
   "metadata": {},
   "source": [
    "## generating a paragraph using transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3077358e-1963-472d-9bfc-95aa1504a013",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated Text:\n",
      "Once upon a time the light in our sky was not to be seen but to behold. And there stood the man in front of these clouds, and heard his roar of trumpets, and said: O son of man, we have heard the trumpet call and the great shout of the great night! And the sun was on the mountain of Horeb, and there stood a man looking at the sky of Eurydice, and saw the great roaring of the great night. And he said: I see you, and behold, I can hear the great voice of the great night! And the great voice of the great night sounded like a shout to all beings. And the great man said to his father and his mother of men, \"O son of man, who loves the world and loves the house, who was sent down from heaven by the power of the heavens, who is in heaven and in earth, who has taken the place of the sons of men, who has gone and\n"
     ]
    }
   ],
   "source": [
    "# Install required libraries\n",
    "# pip install transformers torch tf-keras\n",
    "\n",
    "from transformers import pipeline\n",
    "\n",
    "# Starting a text generation pipeline using a pre-trained model\n",
    "generator = pipeline(\"text-generation\", model=\"gpt2\")\n",
    "\n",
    "# Start prompt\n",
    "prompt = \"Once upon a time\"\n",
    "\n",
    "# Generate a long paragraph\n",
    "output = generator(\n",
    "    prompt, \n",
    "    max_length=200,  \n",
    "    truncation=True  \n",
    ")\n",
    "\n",
    "# Print the result\n",
    "print(\"Generated Text:\")\n",
    "print(output[0]['generated_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e52bfef9-d162-40f4-ab50-ada2499d6426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while True:\n",
    "    # Read each frame from the webcam\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to grab frame. Exiting...\")\n",
    "        break\n",
    "    \n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(30, 30))\n",
    "    \n",
    "    for (x, y, w, h) in faces:\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (255, 0, 0), 2)\n",
    "    \n",
    "    cv2.imshow('Face Detection', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        breakq\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7373dc1-6301-49dd-bf8e-c770ddcad08b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
